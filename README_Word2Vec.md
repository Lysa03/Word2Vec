# üé¨ Word2Vec - Analyse S√©mantique des Films

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Gensim](https://img.shields.io/badge/Gensim-4.3+-green.svg)](https://radimrehurek.com/gensim/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## üìã Description

Ce projet impl√©mente un mod√®le **Word2Vec** entra√Æn√© sur le dataset Kaggle Movies pour apprendre des repr√©sentations vectorielles (embeddings) des mots √† partir des synopsis de films. Le mod√®le capture les relations s√©mantiques entre les mots du domaine cin√©matographique.

## üéØ Objectifs

- Pr√©traiter un corpus de descriptions de films
- Entra√Æner un mod√®le Word2Vec avec Gensim
- Explorer les similarit√©s s√©mantiques entre mots
- Visualiser les embeddings en 2D avec t-SNE
- √âvaluer les performances via des tests d'analogies

## üìä Dataset

**Source** : [Kaggle Movies Dataset](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset)

Le dataset contient des m√©tadonn√©es de films incluant :
- Titres et synopsis (descriptions)
- Genres, dates de sortie
- Informations de production

## üõ†Ô∏è Installation

### Pr√©requis

```bash
Python 3.8+
```

### D√©pendances

```bash
pip install gensim pandas nltk matplotlib seaborn scikit-learn numpy
```

Ou via le fichier requirements :

```bash
pip install -r requirements.txt
```

### T√©l√©chargement des ressources NLTK

```python
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
```

## üìÅ Structure du Projet

```
word2vec-movies/
‚îÇ
‚îú‚îÄ‚îÄ word2vec_movies.ipynb    # Notebook principal
‚îú‚îÄ‚îÄ word2vec_movies.model    # Mod√®le entra√Æn√© (g√©n√©r√©)
‚îú‚îÄ‚îÄ movies_metadata.csv      # Dataset (√† t√©l√©charger)
‚îú‚îÄ‚îÄ README.md                # Ce fichier
‚îî‚îÄ‚îÄ requirements.txt         # D√©pendances
```

## üöÄ Utilisation

### 1. Ex√©cuter le notebook

```bash
jupyter notebook word2vec_movies.ipynb
```

### 2. Charger un mod√®le pr√©-entra√Æn√©

```python
from gensim.models import Word2Vec

# Charger le mod√®le
model = Word2Vec.load("word2vec_movies.model")

# Trouver les mots similaires
similar_words = model.wv.most_similar("love", topn=5)
print(similar_words)

# Test d'analogie
result = model.wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=1)
print(result)  # -> queen
```

## üìà R√©sultats

### Performances Globales

| M√©trique | Valeur |
|----------|--------|
| Score moyen de similarit√© | **0.581** |
| M√©diane | 0.567 |
| √âcart-type | 0.082 |

### Tests de Similarit√©

| Mot | Top 3 mots similaires |
|-----|----------------------|
| `love` | falls (0.72), meets (0.64), romantic (0.57) |
| `family` | father (0.67), mother (0.65), home (0.64) |
| `murder` | case (0.62), crime (0.60), detective (0.57) |
| `hero` | villain (0.41), army (0.40), world (0.39) |

### Tests d'Analogies

| Analogie | R√©sultat attendu | R√©sultat obtenu | Score |
|----------|------------------|-----------------|-------|
| king - man + woman | queen | ‚úÖ queen | 0.550 |
| evil - good + hero | villain | ‚ö†Ô∏è villain (3√®me) | 0.388 |

### Visualisations t-SNE

Le mod√®le produit des clusters coh√©rents :
- **Genres** : thriller/horror proches, documentary isol√©
- **Famille** : father, mother, son, daughter regroup√©s
- **Personnages** : hero, villain dans des zones proches

## ‚öôÔ∏è Hyperparam√®tres du Mod√®le

```python
Word2Vec(
    sentences=corpus,
    vector_size=100,    # Dimension des vecteurs
    window=5,           # Taille de la fen√™tre contextuelle
    min_count=5,        # Fr√©quence minimale des mots
    workers=4,          # Parall√©lisation
    sg=0,               # CBOW (0) ou Skip-gram (1)
    epochs=10           # Nombre d'it√©rations
)
```

## üîç Analyse des R√©sultats

### Points Forts

‚úÖ Excellente capture des relations s√©mantiques th√©matiques (famille, romance, crime)

‚úÖ Analogie classique "king - man + woman = queen" r√©ussie

‚úÖ Clusters t-SNE visuellement interpr√©tables

‚úÖ Relations contextuelles hero/villain bien captur√©es

### Limites

‚ö†Ô∏è Vocabulaire sp√©cialis√© : "antagonist" absent, "protagonist" peu similaire √† "hero"

‚ö†Ô∏è Relations abstraites moins bien captur√©es (day/night/dark)

‚ö†Ô∏è Biais du corpus orient√© synopsis de films

## üìö R√©f√©rences

- [Word2Vec Paper (Mikolov et al., 2013)](https://arxiv.org/abs/1301.3781)
- [Gensim Documentation](https://radimrehurek.com/gensim/)
- [t-SNE Visualization](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)

## üë§ Auteur

**Lys** - Master 2 Big Data & Business Intelligence, Sorbonne Paris Nord

---

## üìÑ License

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

---

*Projet r√©alis√© dans le cadre du cours de Machine Learning - M2 BIDABI*
